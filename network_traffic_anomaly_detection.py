# -*- coding: utf-8 -*-
"""Network_Traffic_Anomaly_Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1weEG-TA1aiq-LgBwAfYu7FondEvpSeak
"""

#google drive connect

from google.colab import drive
drive.mount('/content/drive')

!pip install catboost
!pip install xgboost
!pip install lightgbm

#Import section

import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#ML classification models
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import SGDClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, SpatialDropout1D,BatchNormalization
from tensorflow.keras.optimizers import Adam

#ML evaluation metrics
from sklearn.metrics import accuracy_score, precision_score, recall_score,f1_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

seed=42

"""**Data collection:-**

**About Dataset-**

https://www.kaggle.com/datasets/ziya07/network-traffic-anomaly-detection-dataset/data


This dataset contains network traffic data generated for the purpose of anomaly detection in embedded systems, specifically targeting security threats such as malicious activities. It includes both normal and anomalous (malicious) behavior, which are labeled accordingly for supervised learning tasks. The data encompasses various network traffic features such as packet size, inter-arrival times, protocol types, source and destination IPs, TCP flags, and additional frequency-domain characteristics derived from the Wavelet Transform (WT) method.

The dataset is designed to simulate real-world scenarios involving embedded systems in networked environments, particularly within Internet of Things (IoT) applications, industrial control systems, and critical infrastructure networks. It aims to support the development of advanced anomaly detection models based on deep learning techniques like the Adaptive Differential Evolution Weighted Deep Belief Network (ADE-WDBN), providing both time and resource-efficient solutions to network security challenges.

Key Features:

Packet Size: Size of the network packet in bytes.

Inter-Arrival Time: Time difference between consecutive packets.

Protocol Type: Type of protocol used (TCP, UDP, ICMP).

Source and Destination IP: IP addresses of the source and destination systems.

TCP Flags: Flags in the TCP header indicating the state of the connection.

Packet Count (5s): Number of packets transmitted in a 5-second window.

Spectral Entropy: Frequency-domain feature extracted using Wavelet Transform.

Frequency Band Energy: Energy within different frequency bands derived from Wavelet Transform.

Target Column:
Label: 0 for normal traffic, 1 for anomalous (malicious) traffic.

"""

data=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/embedded_system_network_security_dataset.csv')
data.head(10)

"""**Statistical Analysis:-**"""

#Summary of dataset

data.info()

#size of dataset

data.shape

#Describe dataset

data.describe()

#Check frequency of label

data['label'].value_counts()

"""Observations-
1. packet_size, inter_arrival_time, packet_count_5s are having min value as 0. Let's explore those records.
"""

data[data['packet_size']==0]

data[data['inter_arrival_time']==0]

data['mean_packet_size'].value_counts()

#Dropping mean_packet_size as all values are same

data.drop('mean_packet_size', axis=1, inplace=True)

data[data['label']==1]

data[data['label']==0]

#Check n/a values

data.isna().sum()

#Convert boolean values using label encoding

label_encoder = LabelEncoder()
data['protocol_type_TCP'] = label_encoder.fit_transform(data['protocol_type_TCP'])
data['protocol_type_UDP'] = label_encoder.fit_transform(data['protocol_type_UDP'])
data['src_ip_192.168.1.2'] = label_encoder.fit_transform(data['src_ip_192.168.1.2'])
data['src_ip_192.168.1.3'] = label_encoder.fit_transform(data['src_ip_192.168.1.3'])
data['dst_ip_192.168.1.5'] = label_encoder.fit_transform(data['dst_ip_192.168.1.5'])
data['dst_ip_192.168.1.6'] = label_encoder.fit_transform(data['dst_ip_192.168.1.6'])
data['tcp_flags_FIN'] = label_encoder.fit_transform(data['tcp_flags_FIN'])
data['tcp_flags_SYN'] = label_encoder.fit_transform(data['tcp_flags_SYN'])
data['tcp_flags_SYN-ACK'] = label_encoder.fit_transform(data['tcp_flags_SYN-ACK'])

data.head()

"""No null or na values"""

plt.figure(figsize=(16, 12)) # Increase figure size
sns.heatmap(data.corr(), annot=True, fmt=".2f", cmap="coolwarm", annot_kws={"size": 8}) # Add formatting for annotations, colormap, and font size
plt.title('Correlation Matrix of Features', fontsize=16)
plt.xticks(fontsize=10, rotation=90)
plt.yticks(fontsize=10, rotation=0)
plt.show()

"""Observations-

i. There is no direct correlation of any features with "Label".
ii. src_ip fields are correlated.
iii. dst_ip fields are correlated.
iv. tcp_flag fields are correlated.

It means there is huge possibility of PCA.
"""

#Create a function to check value_counts for all fields

def value_counts(df):
  for col in df.columns:
    print(f"Value counts for column '{col}':")
    print(df[col].value_counts())
    print("\n")

value_counts(data)

"""Observations-

1. Most of boolean fields are imbalanced.
2. Label is also imbalanced.
"""

#Create a function to check outliers

def check_outliers(df):
  for col in df.columns:
    plt.figure(figsize=(8, 6))
    sns.boxplot(x=df[col])
    plt.title(f'Box Plot of {col}')
    plt.show()

check_outliers(data)

"""Observations-

The dataset does not seem to have any outlier problem.

**Anomaly detection algorithms:-**
"""

#Define features and target

X=data.drop('label', axis=1)
y=data['label']

print(X.shape)
print(y.shape)

#Applying standard scaling to normalize the data

scaler=StandardScaler()
X=scaler.fit_transform(X)
print(X.shape)
print(X)

#Using train and test split

X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.25, random_state=seed)
print(X_train.shape)
print(X_test.shape)

"""As target variable is highly imbalanced, considering **SMOTE** method to use."""

#Define function to call all ML Models

def ML_Models(X_train, X_test, y_train, y_test):

  ratio=y_train.value_counts()[0]/y_train.value_counts()[1]

  models={
      "LogReg":LogisticRegression(multi_class='auto',solver='saga', max_iter=100,class_weight='balanced'),
      "KNN": KNeighborsClassifier(),
      "DecTreeCls":DecisionTreeClassifier(criterion='entropy',max_depth=6,random_state=100,min_samples_leaf=5),
      "RanForCls":RandomForestClassifier(n_estimators=100, max_depth=5),
      "SGDCls": SGDClassifier(random_state=seed),
      "SVC": SVC(random_state=seed),
      "XGBoost": XGBClassifier(scale_pos_weight=ratio),
      "LightGBM": LGBMClassifier(scale_pos_weight=ratio),
      "CatBoost": CatBoostClassifier(scale_pos_weight=ratio)
  }

  names = []
  accuracy_scores = []
  precision_scores = []
  recall_scores = []
  f1_scores = []

  for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    accuracy_scores.append(accuracy_score(y_test, y_pred))
    precision_scores.append(precision_score(y_test, y_pred, average='weighted')) # Use weighted for multi-class
    recall_scores.append(recall_score(y_test, y_pred, average='weighted'))
    f1_scores.append(f1_score(y_test, y_pred, average='weighted'))
    names.append(name)

  result_df=pd.DataFrame({
      'model': names,
      'accuracy': accuracy_scores,
      'precision': precision_scores,
      'recall': recall_scores,
      'f1_score': f1_scores
  })
  return result_df

#Verifying accuracy with Logistric Regression method

ML_Models(X_train, X_test, y_train, y_test)

#Let's apply SMOTE

from imblearn.over_sampling import SMOTE
sm = SMOTE()
X_res, y_res = sm.fit_resample(X, y)
print('Smote dataset size:')
print(X_res.shape)
print(y_res.shape)
X_train_sm, X_test_sm, y_train_sm, y_test_sm = train_test_split(X_res, y_res, test_size=0.2, random_state=42)
print('Smore train and test dataset size:')
print(X_train_sm.shape)
print(X_test_sm.shape)

#Verifying accuracy with SMOTE Logistic Regression method

ML_Models(X_train_sm, X_test_sm, y_train_sm, y_test_sm)

"""Observations-
1. XGBoost, LightGBM, CatBoost are best models. Catboost is giving max accuracy, precision, f1_score and recall which is close to 94.5%
"""

#Define features and target

X=data.drop('label', axis=1)
y=data['label']

print(X.shape)
print(y.shape)

# Applying principal component Analysis (PCA) to understand the top features impacting target variable
from sklearn.decomposition import PCA
pca = PCA(n_components=10)
X_pca = pca.fit_transform(X)
print(X_pca.shape)
print("Explained variance ratio:", pca.explained_variance_ratio_)
print("Cumulative variance:", np.cumsum(pca.explained_variance_ratio_))
print("Principal Components (Loadings):")
print(pca.components_)

# Convert X_pca to a DataFrame with named components for better readability
X_pca_df = pd.DataFrame(X_pca, columns=[f'PC{i+1}' for i in range(pca.n_components_)])
print("\nFirst 5 rows of X_pca_df (the 10 new features):")
print(X_pca_df.head())

plt.figure(figsize=(6,4))
plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o')
plt.xlabel("Number of Components")
plt.ylabel("Cumulative Explained Variance")
plt.title("PCA Explained Variance")
plt.grid(True)
plt.show()

"""Depiction-

The table above shows the Principal Component (PC) loadings. Each row (PC1 to PC10) represents a principal component, and each column represents one of your original features. The values in the table indicate the strength and direction of the relationship between each feature and the corresponding principal component.


A larger absolute value in a cell means that the feature has a stronger influence on that specific principal component. For instance:

PC1 is almost entirely dominated by src_port (loading of 1.0), indicating that this feature is the primary driver of the first principal component.

PC2 is strongly influenced by dst_port (loading of 1.0).

PC3 shows significant contributions from protocol_type_TCP, protocol_type_UDP, src_ip_192.168.1.3, dst_ip_192.168.1.5, and dst_ip_192.168.1.6, suggesting that this component captures variations related to these network properties.
Similarly, other principal components are linear combinations of different features, where the loadings quantify each feature's contribution. For example, PC6 has strong negative loading on tcp_flags_FIN and strong positive loading on tcp_flags_SYN-ACK.

This analysis helps in understanding which original features contribute most to the variance captured by each principal component, providing insights into the underlying structure of your data.

"""

#Using X_pca in ML_Models

X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.2, random_state=42)

ML_Models(X_train_pca, X_test_pca, y_train_pca, y_test_pca)

"""Observation-

1. When we apply PCA with 10 components, SVC, Random Forest gives best accuracy, f1_score which is 91.5% and 88% respectively.

Let's apply neural network. LSTM or Bidirectioanl LSTM are not a good choice here as each rows are independent, non-dependent on time series.
"""

#set a random seed to achieve consistent results
tf.random.set_seed(0)

#Define CNN model

model = Sequential([
    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
    BatchNormalization(),
    Dropout(0.2),

    Dense(32, activation='relu'),
    BatchNormalization(),
    Dropout(0.1),

    Dense(16, activation='relu'),

    Dense(1, activation='sigmoid')
])

#Train CNN model

model.compile(optimizer=Adam(learning_rate=0.0008), loss='binary_crossentropy', metrics=['accuracy', 'Precision', 'Recall'])

model.summary()

history=model.fit(X_train,y_train,epochs=100,batch_size=32, validation_split=0.1, verbose=1)

loss, accuracy, precision, recall = model.evaluate(X_test, y_test, verbose=0)

print("Test Loss:", loss)
print("Test Accuracy:", accuracy)
print("Test Precision:", precision)
print("Test Recall:", recall)

#Checking with smote data

history=model.fit(X_train_sm,y_train_sm,epochs=100,batch_size=32, validation_split=0.1, verbose=1)

loss, accuracy, precision, recall = model.evaluate(X_test_sm, y_test_sm, verbose=0)

print("Test Loss:", loss)
print("Test Accuracy:", accuracy)
print("Test Precision:", precision)
print("Test Recall:", recall)

#Plot history accuracy, recall, precision

import matplotlib.pyplot as plt

# --- Plot Accuracy ---
plt.figure(figsize=(10,6))
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.title("Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

# --- Plot Loss ---
plt.figure(figsize=(10,6))
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title("Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
plt.show()

# --- Plot Precision ---
plt.figure(figsize=(10,6))
plt.plot(history.history['Precision'], label='Train Precision')
plt.plot(history.history['val_Precision'], label='Val Precision')
plt.title("Precision")
plt.xlabel("Epoch")
plt.ylabel("Precision")
plt.legend()
plt.show()

# --- Plot Recall ---
plt.figure(figsize=(10,6))
plt.plot(history.history['Recall'], label='Train Recall')
plt.plot(history.history['val_Recall'], label='Val Recall')
plt.title("Recall")
plt.xlabel("Epoch")
plt.ylabel("Recall")
plt.legend()
plt.show()

"""***Conclusion-***

i. We have selected a dataset which is having 1000 rows. This is comparatively small file.

ii. We applied label encoder for boolean fields.

iii. We applied standard scaler on numeric fields

iv. We applied almost all ML classifier models out of which SVC, randomforest classifier, boosting models are best models with respect to accuracy, f1_score.

v. As the classes are imbalanced, so we have applied smote.

vi. We have also applied PCA for dimensionality reduction to 10 components.

vii. We have applied neural network as well. It is giving very high accuracy with smote dataset.

viii. PCA accuracy reduction is very minimal close to 2 to 3%.

ix. If a bigger file size can be considered, SMOTE or PCA will have better difference. However, we have seen metric parameters difference with this smaller size of file as well.

x. There are some options like hyperparameter tuning, cross validation are not applied as part of this assignment. This is purely due to small size of the dataset and due to accuracy/f1-score more than 90%.
"""